{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from unsloth import FastVisionModel\n",
    "from models import qwen2vl as qwn\n",
    "from models import phi4vl as phi\n",
    "from models import aya8vl as aya\n",
    "import docdataset as dd\n",
    "import prompt_templates as pt\n",
    "from prompt_templates import TextSchema, TableSchema, TitleSchema, ClassSchema\n",
    "import docfocus as df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/ucu-mt/src\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3.10-mt-vlm/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd /root/ucu-mt/src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dd.download_dataset()['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompting Open-source Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.3.19: Fast Qwen2_5_Vl patching. Transformers: 4.50.3.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 3090. Num GPUs = 1. Max memory: 23.684 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Unsloth: QLoRA and full finetuning all not selected. Switching to 16bit LoRA.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 5/5 [00:02<00:00,  2.37it/s]\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "model = qwn.QwenVL2_LLM(\n",
    "    model_name = \"unsloth/Qwen2.5-VL-7B-Instruct\",\n",
    "    max_new_tokens = 4096,\n",
    "    device = \"cuda\",\n",
    "    load_in_4bit = False,\n",
    "    use_gradient_checkpointing = \"unsloth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:10<00:00,  3.60s/it]\n"
     ]
    }
   ],
   "source": [
    "model = phi.Phi4VisionLLM(\n",
    "    model_name = \"microsoft/Phi-4-multimodal-instruct\",\n",
    "    max_new_tokens = 1000,\n",
    "    device = \"cuda\",\n",
    "    attn_mech = \"flash_attention_2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = aya.AyaVisionLLM(\n",
    "    model_name = \"CohereForAI/aya-vision-8b\",\n",
    "    max_new_tokens = 4096,\n",
    "    device = \"cuda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = qwn.QwenVL2_LLM(\n",
    "    model_name = \"ansu0122/uadoc-ada-qwen2.5vl\",\n",
    "    max_new_tokens = 4096,\n",
    "    device = \"cuda\",\n",
    "    load_in_4bit = False,\n",
    "    use_gradient_checkpointing = \"unsloth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = dataset[-10][\"image\"]\n",
    "\n",
    "model.set_prompt(pt.get_text_template())\n",
    "\n",
    "result = model.process_doc_image(image)\n",
    "\n",
    "if result:\n",
    "    print(\"result:\", result)\n",
    "else:\n",
    "    print(\"Failed to parse the response.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCR Text sections\n",
    "dataset = dataset.shuffle(seed=42)\n",
    "\n",
    "model.set_prompt(pt.get_text_template())\n",
    "df.ocr_dataset(dataset, \"../results/ocr_text_phi4vl.jsonl\", ocr_fn= model.process_doc_image, chunk_size=2, lang=\"ukr\", region_types=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCR Doc sections\n",
    "dataset = dataset.shuffle(seed=42)\n",
    "\n",
    "model.set_prompt(pt.get_text_template())\n",
    "df.ocr_dataset(dataset, \"../results/ocr_whole_doc_phi4vl.jsonl\", ocr_fn= model.process_doc_image, chunk_size=2, lang=\"ukr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table Extraction Table sections\n",
    "dataset = dataset.shuffle(seed=42)\n",
    "\n",
    "model.set_prompt(pt.get_table_template())\n",
    "df.ocr_dataset(dataset, \"../results/table_table_phi4vl.jsonl\", ocr_fn= model.process_doc_image, chunk_size=2, lang=\"ukr\", region_types=[\"table\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table Extraction Doc sections\n",
    "dataset = dataset.shuffle(seed=42)\n",
    "\n",
    "model.set_prompt(pt.get_table_template())\n",
    "df.ocr_dataset(dataset, \"../results/table_whole_doc_phi4vl.jsonl\", ocr_fn= model.process_doc_image, chunk_size=2, lang=\"ukr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layout Analysis Doc sections\n",
    "dataset = dataset.shuffle(seed=42)\n",
    "\n",
    "model.set_prompt(pt.get_title_template())\n",
    "df.ocr_dataset(dataset, \"../results/layout_whole_doc_phi4vl.jsonl\", ocr_fn= model.process_doc_image, chunk_size=2, lang=\"ukr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Doc sections\n",
    "dataset = dataset.shuffle(seed=42)\n",
    "\n",
    "model.set_prompt(pt.get_class_template())\n",
    "df.ocr_dataset(dataset, \"../results/class_whole_doc_phi4vl.jsonl\", ocr_fn= model.process_doc_image, chunk_size=2, lang=\"ukr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Release Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "del model \n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 27 19:34:16 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.107.02             Driver Version: 550.107.02     CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090        On  |   00000000:09:00.0 Off |                  N/A |\n",
      "| 30%   47C    P5             59W /  350W |     300MiB /  24576MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory allocated: 10.12 MB\n",
      "Memory reserved: 40.00 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Memory allocated: {torch.cuda.memory_allocated() / 1024 / 1024:.2f} MB\")\n",
    "print(f\"Memory reserved: {torch.cuda.memory_reserved() / 1024 / 1024:.2f} MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10-mt-vlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
