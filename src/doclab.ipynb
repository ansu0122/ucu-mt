{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3.10-mt-vlm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from unsloth import FastVisionModel\n",
    "from models import qwen2vl_unsloth as qwuns\n",
    "from models import phi4vl as phi\n",
    "import docdataset as dd\n",
    "import prompt_templates as pt\n",
    "import docfocus as df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/ucu-mt/src\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3.10-mt-vlm/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd /root/ucu-mt/src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dd.download_dataset()['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.3.19: Fast Qwen2_5_Vl patching. Transformers: 4.50.3.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 3090. Num GPUs = 1. Max memory: 23.684 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Unsloth: QLoRA and full finetuning all not selected. Switching to 16bit LoRA.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 5/5 [00:02<00:00,  2.37it/s]\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "model = qwuns.QwenVL2_LLM(\n",
    "    model_name = \"unsloth/Qwen2.5-VL-7B-Instruct\",\n",
    "    max_new_tokens = 4096,\n",
    "    device = \"cuda\",\n",
    "    load_in_4bit = False,\n",
    "    use_gradient_checkpointing = \"unsloth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3.10-mt-vlm/lib/python3.10/site-packages/transformers/models/auto/image_processing_auto.py:602: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead\n",
      "  warnings.warn(\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "/root/.cache/huggingface/modules/transformers_modules/microsoft/Phi-4-multimodal-instruct/0ae13bd0f508a906f8b8288fc5e36b01b903c132/speech_conformer_encoder.py:2774: FutureWarning: Please specify CheckpointImpl.NO_REENTRANT as CheckpointImpl.REENTRANT will soon be removed as the default and eventually deprecated.\n",
      "  lambda i: encoder_checkpoint_wrapper(\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:06<00:00,  2.19s/it]\n"
     ]
    }
   ],
   "source": [
    "model = phi.Phi4VisionLLM(\n",
    "    model_name = \"microsoft/Phi-4-multimodal-instruct\",\n",
    "    max_new_tokens = 4096,\n",
    "    device = \"cuda\",\n",
    "    attn_mech = \"eager\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are not running the flash-attention implementation, expect numerical differences.\n",
      "If you are not using the generate method, you may encounter nonsensical outputs after the 4096th token, as the KV cache needs to be recomputed.\n",
      "We detected that you are passing `past_key_values` as a tuple of tuples. This is deprecated and will be removed in v4.47. Please convert your cache or use an appropriate `Cache` class (https://huggingface.co/docs/transformers/kv_cache#legacy-cache-format)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: КЕЙНСІАНСЬКА ФУКЦІЯ ІНВЕСТИЦІЙ\n",
      "Огляд ключісної функції інвестицій\n",
      "Кейсіанська функція інвестицій, розроблена Доном Мейнарлом Кейсом, є популярною методологією для оцінки інвестиційного клімату. Вона базується на концепції такого інвестиційного клімату, як розробленого Доном Мейнарлом Кейсом.\n",
      "Ключові деталі функції та її забезпечення\n",
      "Глобальні елементи ключісної функції інвестицій — це граціна ефективності капіталу, яка визначає витратність інвестицій, і порівняння отриманих прибутків з інвестиційним портфоліо. Відносно інвестиційних проектів, що забезпечують портфоліо та потенційно демонструють обертові прибутки протягом стійкого часу, це важливі для розгляду інвестиційних проектів.\n",
      "Практичні приклади забезпечення функції\n",
      "Реалізація ключісної функції інвестицій вимагає аналіз потенційних стійок і граціни ефективності, щоб забезпечити економічну дійсність проекту. При зменшенні потенційної стійки інвестиційного портфоліо зростає, тому використання більшого проекту при високій ефективності капіталу.\n",
      "Таблиця: Фінансові ефективності інвестиційних проектів\n",
      "| Інвестиція проекту | Граціна ефективності капіталу (%) | Інвестиційний Потік при Ризьких Процентних Ставках | Максімальний Проект | Проект 1 і 2 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і 3 | Проект 1, 2 і \n"
     ]
    }
   ],
   "source": [
    "image = dataset[-10][\"image\"]\n",
    "\n",
    "model.set_prompt(pt.get_text_template())\n",
    "\n",
    "result = model.process_doc_image(image)\n",
    "\n",
    "if result:\n",
    "    print(\"result:\", result)\n",
    "else:\n",
    "    print(\"Failed to parse the response.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCR Text sections\n",
    "dataset = dataset.shuffle(seed=42)\n",
    "\n",
    "model.set_prompt(pt.get_text_template())\n",
    "df.ocr_dataset(dataset, \"../results/ocr_text_qwen25vl.jsonl\", ocr_fn= model.process_doc_image, chunk_size=2, lang=\"ukr\", region_types=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCR Doc sections\n",
    "dataset = dataset.shuffle(seed=42)\n",
    "\n",
    "model.set_prompt(pt.get_text_template())\n",
    "df.ocr_dataset(dataset, \"../results/ocr_whole_doc_qwen25vl.jsonl\", ocr_fn= model.process_doc_image, chunk_size=2, lang=\"ukr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table Extraction Table sections\n",
    "dataset = dataset.shuffle(seed=42)\n",
    "\n",
    "model.set_prompt(pt.get_table_template())\n",
    "df.ocr_dataset(dataset, \"../results/table_table_qwen25vl.jsonl\", ocr_fn= model.process_doc_image, chunk_size=2, lang=\"ukr\", region_types=[\"table\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table Extraction Doc sections\n",
    "dataset = dataset.shuffle(seed=42)\n",
    "\n",
    "model.set_prompt(pt.get_table_template())\n",
    "df.ocr_dataset(dataset, \"../results/table_whole_doc_qwen25vl.jsonl\", ocr_fn= model.process_doc_image, chunk_size=2, lang=\"ukr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layout Analysis Doc sections\n",
    "dataset = dataset.shuffle(seed=42)\n",
    "\n",
    "model.set_prompt(pt.get_title_template())\n",
    "df.ocr_dataset(dataset, \"../results/layout_whole_doc_qwen25vl.jsonl\", ocr_fn= model.process_doc_image, chunk_size=2, lang=\"ukr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Doc sections\n",
    "dataset = dataset.shuffle(seed=42)\n",
    "\n",
    "model.set_prompt(pt.get_class_template())\n",
    "df.ocr_dataset(dataset, \"../results/class_whole_doc_qwen25vl.jsonl\", ocr_fn= model.process_doc_image, chunk_size=2, lang=\"ukr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Release Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "del model \n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in dir():\n",
    "    if isinstance(eval(var), torch.Tensor):\n",
    "        del globals()[var]\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 27 19:34:16 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.107.02             Driver Version: 550.107.02     CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090        On  |   00000000:09:00.0 Off |                  N/A |\n",
      "| 30%   47C    P5             59W /  350W |     300MiB /  24576MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory allocated: 10.12 MB\n",
      "Memory reserved: 40.00 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Memory allocated: {torch.cuda.memory_allocated() / 1024 / 1024:.2f} MB\")\n",
    "print(f\"Memory reserved: {torch.cuda.memory_reserved() / 1024 / 1024:.2f} MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10-mt-vlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
